{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Given users review predit overall rating given by user\r\n",
    "import json\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "import string\r\n",
    "        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# read json data\r\n",
    "raw_data = pd.read_json(\"./dataset/Music_Review_train.json\",lines=True)\r\n",
    "X=raw_data['reviewText']\r\n",
    "Y=raw_data['overall']\r\n",
    "# preprocess data\r\n",
    "def preprocess_data(X):\r\n",
    "    sw_nltk=set(stopwords.words('english'))\r\n",
    "    \r\n",
    "    output=[]\r\n",
    "    for sentence in X:\r\n",
    "        # tokenize sentence\r\n",
    "        tokens=word_tokenize(sentence)\r\n",
    "        # normalize\r\n",
    "        tokens=[w.lower() for w in tokens]\r\n",
    "        # remove punctuation\r\n",
    "        table=str.maketrans('','',string.punctuation)\r\n",
    "        stripped=[w.translate(table) for w in tokens]\r\n",
    "        # remove remaining tokens that are not alphabetic\r\n",
    "        words=[word for word in stripped if word.isalpha()]\r\n",
    "        # filter out stop words\r\n",
    "        words=[w for w in words if not w in sw_nltk]\r\n",
    "        # filter out stem words\r\n",
    "        ps=PorterStemmer()\r\n",
    "        words=[ps.stem(w) for w in words]\r\n",
    "        output.append(words)\r\n",
    "    return output\r\n",
    "temp_X=preprocess_data(X)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKFE1P1ZDBPXU</td>\n",
       "      <td>B000002IWQ</td>\n",
       "      <td>M. B. Link \"wildfirelink\"</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>Counterparts(1993). Rush's fifteenth studio al...</td>\n",
       "      <td>4</td>\n",
       "      <td>Underrated and Overrated Simultaneously</td>\n",
       "      <td>1067904000</td>\n",
       "      <td>11 4, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A10CBLMJD1OQL7</td>\n",
       "      <td>B000002IWQ</td>\n",
       "      <td>mcmahonryan@hotmail.com</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>You have to ask yourself why, in 1998, there a...</td>\n",
       "      <td>4</td>\n",
       "      <td>Rush continues to reinvent itself</td>\n",
       "      <td>900633600</td>\n",
       "      <td>07 17, 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A331OF34UX4Y1K</td>\n",
       "      <td>B000002IWQ</td>\n",
       "      <td>M. Fonseca \"carmarthen\"</td>\n",
       "      <td>[2, 9]</td>\n",
       "      <td>I've bought this CD a long time ago and until ...</td>\n",
       "      <td>2</td>\n",
       "      <td>THE WEAKEST RUSH ALBUM EVER !</td>\n",
       "      <td>944006400</td>\n",
       "      <td>12 1, 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A18IZ5QX2PRB3C</td>\n",
       "      <td>B000002IWQ</td>\n",
       "      <td>Michael Stack</td>\n",
       "      <td>[80, 83]</td>\n",
       "      <td>I am often in the minority in my view of this,...</td>\n",
       "      <td>5</td>\n",
       "      <td>Rush's '90s masterpiece.</td>\n",
       "      <td>1111536000</td>\n",
       "      <td>03 23, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2H22I2RWE0HOV</td>\n",
       "      <td>B000002IWQ</td>\n",
       "      <td>Mr. Sinister</td>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>The first thing that becomes apparent as soon ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Counterparts Shifts The Rush Sound Once Again</td>\n",
       "      <td>1184025600</td>\n",
       "      <td>07 10, 2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin               reviewerName   helpful  \\\n",
       "0   AKFE1P1ZDBPXU  B000002IWQ  M. B. Link \"wildfirelink\"    [4, 5]   \n",
       "1  A10CBLMJD1OQL7  B000002IWQ    mcmahonryan@hotmail.com    [0, 0]   \n",
       "2  A331OF34UX4Y1K  B000002IWQ    M. Fonseca \"carmarthen\"    [2, 9]   \n",
       "3  A18IZ5QX2PRB3C  B000002IWQ              Michael Stack  [80, 83]   \n",
       "4  A2H22I2RWE0HOV  B000002IWQ               Mr. Sinister    [3, 6]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Counterparts(1993). Rush's fifteenth studio al...        4   \n",
       "1  You have to ask yourself why, in 1998, there a...        4   \n",
       "2  I've bought this CD a long time ago and until ...        2   \n",
       "3  I am often in the minority in my view of this,...        5   \n",
       "4  The first thing that becomes apparent as soon ...        4   \n",
       "\n",
       "                                         summary  unixReviewTime   reviewTime  \n",
       "0        Underrated and Overrated Simultaneously      1067904000   11 4, 2003  \n",
       "1              Rush continues to reinvent itself       900633600  07 17, 1998  \n",
       "2                  THE WEAKEST RUSH ALBUM EVER !       944006400   12 1, 1999  \n",
       "3                       Rush's '90s masterpiece.      1111536000  03 23, 2005  \n",
       "4  Counterparts Shifts The Rush Sound Once Again      1184025600  07 10, 2007  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4\n",
       "1    4\n",
       "2    2\n",
       "3    5\n",
       "4    4\n",
       "Name: overall, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_vocabulary(X_c):\r\n",
    "    class_vocab=[]\r\n",
    "    unique,counts=np.unique(X_c,return_counts=True)\r\n",
    "    vocab=dict(zip(unique,counts))\r\n",
    "    class_vocab.append(vocab)    \r\n",
    "    for class_label in range(5):\r\n",
    "        unique,counts=np.unique(X_c[np.where(Y==class_label)],return_counts=True)\r\n",
    "        vocab=dict(zip(unique,counts))\r\n",
    "        class_vocab.append(vocab)\r\n",
    "    return class_vocab\r\n",
    "    \r\n",
    "    # # vocab is list of dictionaries\r\n",
    "    \r\n",
    "    # vocab=[]\r\n",
    "    # # map to store frequency\r\n",
    "    # maps=[{},{},{},{},{}]\r\n",
    "    # class_occur=[0,0,0,0,0]\r\n",
    "    # for i in range(len(X_c)):\r\n",
    "    #     # iterate over ith example\r\n",
    "    #     class_label=Y[i]-1\r\n",
    "    #     class_occur[class_label]+=1\r\n",
    "    #     for word in X_c[i]:\r\n",
    "    #         # iterate over features of ith example\r\n",
    "    #         if word not in vocab[class_label]:\r\n",
    "    #             vocab[class_label].add(word)\r\n",
    "    #         else:\r\n",
    "    #             maps[class_label][word]+=1\r\n",
    "    # return vocab,map\r\n",
    "\r\n",
    "# Naive bayes from scratch\r\n",
    "def naive_bayes(X,Y,vocab):\r\n",
    "    # number of examples = m\r\n",
    "    m=len(X)\r\n",
    "    # class then vocabulary\r\n",
    "    psi_i=[[]]\r\n",
    "    psi_y=None\r\n",
    "    # get vocabulary\r\n",
    "    vocab=get_vocabulary(X)\r\n",
    "    iter=0\r\n",
    "    for class_label in range(5):\r\n",
    "        denom=sum([len(row) for row in X[np.where(Y==class_label)]])\r\n",
    "        for word in vocab[0]:\r\n",
    "            psi_i[class_label].append(vocab[class_label+1][word]/denom)\r\n",
    "            iter+=1\r\n",
    "    psi_y=len(np.where(Y==1))/m\r\n",
    "    return psi_i,psi_y\r\n",
    "\r\n",
    "def predict(x,psi_i,psi_y):\r\n",
    "    class_prob=[]\r\n",
    "    denom=1\r\n",
    "    for class_label in range(5):\r\n",
    "        numer=1\r\n",
    "        for word in x:\r\n",
    "            # start from here again\r\n",
    "            numer*=psi_i[class_label][word]\r\n",
    "            denom=None\r\n",
    "        p_y_x=numer\r\n",
    "        class_prob.append(p_y_x)\r\n",
    "    class_prob/=denom\r\n",
    "    return class_prob        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(len(X))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91930\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "X=np.array([[1,2,3,4,5],[5,2,3,4,5],[1,2,3,4],[3,4,5],[1,2,3,4,5]])\r\n",
    "Y=np.array([1,1,1,0,1])\r\n",
    "len(X[np.where(Y==1)])\r\n",
    "temp=sum([len(row) for row in X[np.where(Y==1)]]) \r\n",
    "print(temp)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-20-95fd7c8df35e>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X=np.array([[1,2,3,4,5],[5,2,3,4,5],[1,2,3,4],[3,4,5],[1,2,3,4,5]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(np.where(Y==1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "af74d5892cc6ec92d638e3f92566238f8f2331de277a6f0ed89e3a87c5669053"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}