{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# copy first n lines of \"./dataset/Music_Review_train.json\" and store it to \"./dataset/Music_Review_train_temp.json\"\r\n",
    "with open(\"./dataset/Music_Review_test.json\", \"r\") as f:\r\n",
    "    lines = f.readlines()\r\n",
    "    with open(\"./dataset/Music_Review_test_temp.json\", \"w\") as f:\r\n",
    "        for line in lines[:1000]:\r\n",
    "            f.write(line)\r\n",
    "with open(\"./dataset/Music_Review_train.json\", \"r\") as f:\r\n",
    "    lines = f.readlines()\r\n",
    "    with open(\"./dataset/Music_Review_train_temp.json\", \"w\") as f:\r\n",
    "        for line in lines[:1000]:\r\n",
    "            f.write(line)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\r\n",
    "X=np.load('X_test_clean_tr_q1.npy',allow_pickle=True)\r\n",
    "print(X.shape)\r\n",
    "X=np.load('X_test_clean_q1.npy',allow_pickle=True)\r\n",
    "print(X.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14000,)\n",
      "(14000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X=np.load('X_train_clean_tr_q1.npy',allow_pickle=True)\r\n",
    "print(X.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "\r\n",
    "# import these modules\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    " \r\n",
    "lemmatizer = WordNetLemmatizer()\r\n",
    " \r\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\r\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\r\n",
    " \r\n",
    "# a denotes adjective in \"pos\"\r\n",
    "print(\"better :\", lemmatizer.lemmatize(\"of\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : of\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import nltk\r\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91930\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "mydict={'a':1,'b':2,'c':3}\r\n",
    "print(len(mydict))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "m = np.array([[1,2,3],[4,5,6],[7,8,9]])\r\n",
    "\r\n",
    "c = np.array([0,1,2])\r\n",
    "t=c*m\r\n",
    "print(t)\r\n",
    "print(t*t.T)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0  2  6]\n",
      " [ 0  5 12]\n",
      " [ 0  8 18]]\n",
      "[[  0   0   0]\n",
      " [  0  25  96]\n",
      " [  0  96 324]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from PIL import Image\r\n",
    "import numpy as np\r\n",
    "from libsvm.svmutil import *\r\n",
    "\r\n",
    "# load model\r\n",
    "model = svm_load_model('model.txt')\r\n",
    "print(model) \r\n",
    "# generate image from 1d array of 784 pixels\r\n",
    "t=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,117,254,220,89,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,95,212,253,253,253,157,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,95,209,253,253,253,245,125,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,40,96,206,253,254,253,253,198,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,182,240,253,253,253,254,253,198,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,60,60,168,253,253,254,200,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,70,247,253,253,245,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,207,253,253,207,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,219,253,253,253,138,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,105,250,253,253,253,34,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,95,254,254,254,254,94,0,0,0,0,0,3,13,13,13,8,0,0,0,0,0,0,0,0,0,0,0,0,107,253,253,253,204,15,0,0,0,0,21,166,253,253,253,212,25,0,0,0,0,0,0,0,0,0,0,33,217,253,253,132,64,0,0,18,43,157,171,253,253,253,253,253,160,2,0,0,0,0,0,0,0,0,3,166,253,253,242,49,17,49,158,210,254,253,253,253,253,253,253,253,253,11,0,0,0,0,0,0,0,0,10,227,253,253,207,15,172,253,253,253,254,247,201,253,210,210,253,253,175,4,0,0,0,0,0,0,0,0,10,228,253,253,224,87,242,253,253,184,60,54,9,60,35,182,253,253,52,0,0,0,0,0,0,0,0,0,13,253,253,253,253,231,253,253,253,93,86,86,86,109,217,253,253,134,5,0,0,0,0,0,0,0,0,0,2,115,253,253,253,253,253,253,253,253,254,253,253,253,253,253,134,5,0,0,0,0,0,0,0,0,0,0,0,3,166,253,253,253,253,253,253,253,254,253,253,253,175,52,5,0,0,0,0,0,0,0,0,0,0,0,0,0,7,35,132,225,253,253,253,195,132,132,132,110,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]).reshape(28,28)\r\n",
    "img = Image.fromarray(t)\r\n",
    "# save image\r\n",
    "print(model.)\r\n",
    "img.convert('RGB').save('test.jpeg')\r\n",
    "img.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<svm.svm_model object at 0x000001CA94E67340>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# read 0th column from csv file\r\n",
    "import pandas as pd\r\n",
    "df = pd.read_csv('./multi-libsvm-miss/missclassified_test.csv', usecols=[0],header=None)\r\n",
    "data=pd.read_csv('./dataset/test.csv',header=None)\r\n",
    "# select all but last column\r\n",
    "data=data.iloc[:,:-1]\r\n",
    "data=np.array(data)\r\n",
    "df=np.array(df)\r\n",
    "for i in range(len(df)):\r\n",
    "    print(df[i])\r\n",
    "    img=Image.fromarray(np.array(data[df[i][0]]).reshape(28,28).astype(np.uint8))\r\n",
    "    img.convert('RGB').save(\"./multi-libsvm-miss/miss_test_\"+str(i)+\".jpeg\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2087]\n",
      "[2675]\n",
      "[3739]\n",
      "[4377]\n",
      "[4441]\n",
      "[6240]\n",
      "[6383]\n",
      "[7572]\n",
      "[9187]\n",
      "[9323]\n",
      "[9473]\n",
      "[10820]\n",
      "[11339]\n",
      "[13098]\n",
      "[13483]\n",
      "[14533]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(df[0][0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2675\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\r\n",
    "final_pred_train=np.array([{10:1,20:1},{10:2,20:2},{10:3,20:3},{10:4,20:4},{10:5,20:5},{10:6,20:6},{10:7,20:7},{10:8,20:8}])\r\n",
    "Y_pred_train=np.array([1,1,1,1,-1,-1,-1,-1])\r\n",
    "temp=final_pred_train\r\n",
    "print(final_pred_train[np.where(Y_pred_train==1)])\r\n",
    "print(final_pred_train[np.where(Y_pred_train==1)][0])\r\n",
    "final_pred_train[np.where(Y_pred_train==1)][10]+=1\r\n",
    "final_pred_train[np.where(Y_pred_train==-1)][20]+=1\r\n",
    "print(final_pred_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{10: 1, 20: 1} {10: 2, 20: 2} {10: 3, 20: 3} {10: 4, 20: 4}]\n",
      "{10: 1, 20: 1}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 4",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d18bf0b0cd71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_pred_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred_train\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_pred_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred_train\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfinal_pred_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred_train\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mfinal_pred_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred_train\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_pred_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "alpha=np.array([1,2])\r\n",
    "supp=np.array([[1,2,3,4],[1,2,3,5]])\r\n",
    "\r\n",
    "supp_y=np.array([1,1])\r\n",
    "X=np.array([[10,1,1,1],[1,1,1,1],[1,1,1,1]])\r\n",
    "print(X[0]-supp)\r\n",
    "a=np.dot(alpha,np.diag(supp_y))\r\n",
    "print(a)\r\n",
    "b=np.exp(-0.05*np.linalg.norm(X[0]-supp,axis=1)**2)\r\n",
    "print(b)\r\n",
    "c=np.diag(b)\r\n",
    "c=np.dot(a,c)\r\n",
    "print(c)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 9 -1 -2 -3]\n",
      " [ 9 -1 -2 -4]]\n",
      "[1 2]\n",
      "[0.0086517  0.00609675]\n",
      "[0.0086517  0.01219349]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "squarer = lambda x: np.sum(np.dot(np.dot(alpha,np.diag(supp_y)),np.diag(np.exp(-0.05*np.linalg.norm(x-supp,axis=1)**2))))\r\n",
    "print(X)\r\n",
    "pred=np.apply_along_axis(squarer,1,X)\r\n",
    "print(pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[10  1  1  1]\n",
      " [ 1  1  1  1]\n",
      " [ 1  1  1  1]]\n",
      "[0.02084519 1.1964608  1.1964608 ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "a=np.array([1,2,3,4])\r\n",
    "b=np.array([1,2,3,5])\r\n",
    "print(a*b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1  4  9 20]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "af74d5892cc6ec92d638e3f92566238f8f2331de277a6f0ed89e3a87c5669053"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}