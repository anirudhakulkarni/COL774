A
onehot
Training accuracy 
Testing accuracy 
Validation accuracy
[0.8835987613359876, 0.8964001327140013, 0.8964001327140013, 0.8968701614687016, 0.8985843839858438, 0.9023999115239991, 0.9035611590356116, 0.905966600309666, 0.9072660915726609, 0.9088697190886972, 0.9194591904445919, 0.934555408095554, 0.9568679495686795, 0.9791528422915284, 0.9954656049546561]        
[0.8752488387524884, 0.8880778588807786, 0.8880778588807786, 0.8885202388852024, 0.893607608936076, 0.8962618889626189, 0.8953771289537713, 0.8958195089581951, 0.896040698960407, 0.8953771289537713, 0.8940499889404999, 0.8865295288652952, 0.880557398805574, 0.8750276487502765, 0.8723733687237337]
[0.8861123396727112, 0.891640866873065, 0.891640866873065, 0.8929677134011499, 0.8898717381689518, 0.8929677134011499, 0.8942945599292349, 0.897390535161433, 0.8978328173374613, 0.8971693940734189, 0.9038036267138434, 0.8962848297213623, 0.8889871738168952, 0.8803626713843432, 0.8721804511278195]
[3, 7, 15, 27, 49, 81, 127, 191, 269, 367, 1375, 3607, 6863, 10047, 12335]

Multi way
[0.8835987613359876, 0.8964001327140013, 0.8967595664675957, 0.8985567352355673, 0.9011004202610042, 0.9083443928334439, 0.9170537491705375, 0.9261778367617783, 0.9370437956204379, 0.9484074319840743, 0.9910141561601415, 1.0, 1.0, 1.0, 1.0]
[0.8752488387524884, 0.8880778588807786, 0.8882990488829905, 0.8865295288652952, 0.8867507188675072, 0.8927228489272285, 0.8889626188896262, 0.8818845388188454, 0.876133598761336, 0.8763547887635479, 0.8639681486396815, 0.8613138686131386, 0.8613138686131386, 0.8613138686131386, 0.8613138686131386]
[0.8861123396727112, 0.891640866873065, 0.8909774436090225, 0.8911985846970367, 0.8925254312251216, 0.8896505970809376, 0.8898717381689518, 0.888766032728881, 0.8874391862007961, 0.8854489164086687, 0.8721804511278195, 0.8695267580716497, 0.8695267580716497, 0.8695267580716497, 0.8695267580716497]
[3, 9, 49, 367, 988, 1899, 3052, 4553, 6204, 7831, 13045, 14020, 14020, 14020, 14020]

B

One hot
[0.9933919486839194, 0.9795122760451228, 0.9662132271621323, 0.9472185357221854, 0.9310163680601636, 0.9006856890068569]
[0.8723733687237337, 0.8779031187790312, 0.880336208803362, 0.8867507188675072, 0.8891838088918381, 0.8845388188453882]
[0.8737284387439186, 0.8788146837682441, 0.8841220698805838, 0.8863334807607254, 0.891640866873065, 0.8923042901371074]
Multi
prune_train_list=[0.9933919486839194, 0.9795122760451228, 0.9662132271621323, 0.9472185357221854, 0.9310163680601636, 0.9006856890068569]
prune_test_list=[0.8723733687237337, 0.8779031187790312, 0.880336208803362, 0.8867507188675072, 0.8891838088918381, 0.8845388188453882]
prune_val_list=[0.8737284387439186, 0.8788146837682441, 0.8841220698805838, 0.8863334807607254, 0.891640866873065, 0.8923042901371074]

Test accuracy after maximum possible pruning
[0.8752488387524884, 0.8880778588807786, 0.8880778588807786, 0.8885202388852024, 0.8885202388852024, 0.8889626188896262, 0.8885202388852024, 0.8958195089581951, 0.8953771289537713, 0.8942711789427118, 0.8955983189559832, 0.8958195089581951, 0.8880778588807786, 0.8752488387524884, 0.8752488387524884]

c)
oob score: 0.8907597876575979
Train accuracy: 0.9064642778146428
Test accuracy: 0.8843176288431763
Val accuracy: 0.8900928792569659

Previous model after pruning:
0.9006856890068569
0.8845388188453882
0.8923042901371074

d)

